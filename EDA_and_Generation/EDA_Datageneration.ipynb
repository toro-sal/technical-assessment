{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data EDA & Extension to 1000 Rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: 10 11 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "origin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "redeemed_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "dc655952-6443-4f95-9895-a6ff779f2ea3",
       "rows": [
        [
         "0",
         "1",
         "DWEHSP",
         "YouTube",
         "2024-01-10 17:07:01+00:00"
        ],
        [
         "1",
         "2",
         "QGKTBC",
         "Discord",
         "2024-02-13 05:40:50+00:00"
        ],
        [
         "2",
         "3",
         "YRLUJA",
         "X",
         "2024-02-24 04:35:15+00:00"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>code</th>\n",
       "      <th>origin</th>\n",
       "      <th>redeemed_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DWEHSP</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>2024-01-10 17:07:01+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>QGKTBC</td>\n",
       "      <td>Discord</td>\n",
       "      <td>2024-02-13 05:40:50+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>YRLUJA</td>\n",
       "      <td>X</td>\n",
       "      <td>2024-02-24 04:35:15+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    code   origin                redeemed_at\n",
       "0   1  DWEHSP  YouTube  2024-01-10 17:07:01+00:00\n",
       "1   2  QGKTBC  Discord  2024-02-13 05:40:50+00:00\n",
       "2   3  YRLUJA        X  2024-02-24 04:35:15+00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "affiliate_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "country_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_kyc_approved",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "updated_at",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "9dc5ec64-4b8a-4f23-804b-4b8a8532215f",
       "rows": [
        [
         "0",
         "1",
         "1.0",
         "DE",
         "True",
         "2024-01-10 17:07:01+00:00",
         "2024-02-08 09:05:26+00:00"
        ],
        [
         "1",
         "2",
         null,
         "BR",
         "True",
         "2024-02-09 19:19:27+00:00",
         "2024-03-05 08:06:20+00:00"
        ],
        [
         "2",
         "3",
         "2.0",
         "BR",
         "True",
         "2024-02-13 05:40:50+00:00",
         "2024-02-17 10:58:17+00:00"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affiliate_id</th>\n",
       "      <th>country_code</th>\n",
       "      <th>is_kyc_approved</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-01-10 17:07:01+00:00</td>\n",
       "      <td>2024-02-08 09:05:26+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-02-09 19:19:27+00:00</td>\n",
       "      <td>2024-03-05 08:06:20+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>True</td>\n",
       "      <td>2024-02-13 05:40:50+00:00</td>\n",
       "      <td>2024-02-17 10:58:17+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  affiliate_id country_code  is_kyc_approved                 created_at  \\\n",
       "0   1           1.0           DE             True  2024-01-10 17:07:01+00:00   \n",
       "1   2           NaN           BR             True  2024-02-09 19:19:27+00:00   \n",
       "2   3           2.0           BR             True  2024-02-13 05:40:50+00:00   \n",
       "\n",
       "                  updated_at  \n",
       "0  2024-02-08 09:05:26+00:00  \n",
       "1  2024-03-05 08:06:20+00:00  \n",
       "2  2024-02-17 10:58:17+00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "player_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "amount",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "8aebb197-f5de-47b7-b6d5-d7b16f5ae0b2",
       "rows": [
        [
         "0",
         "1",
         "2024-01-10 17:07:01+00:00",
         "7",
         "Withdraw",
         "213.13"
        ],
        [
         "1",
         "2",
         "2024-02-09 19:19:27+00:00",
         "4",
         "Withdraw",
         "182.64"
        ],
        [
         "2",
         "3",
         "2024-02-13 05:40:50+00:00",
         "8",
         "Withdraw",
         "184.22"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>player_id</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-10 17:07:01+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>Withdraw</td>\n",
       "      <td>213.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-02-09 19:19:27+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Withdraw</td>\n",
       "      <td>182.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-02-13 05:40:50+00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>Withdraw</td>\n",
       "      <td>184.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                  timestamp  player_id      type  amount\n",
       "0   1  2024-01-10 17:07:01+00:00          7  Withdraw  213.13\n",
       "1   2  2024-02-09 19:19:27+00:00          4  Withdraw  182.64\n",
       "2   3  2024-02-13 05:40:50+00:00          8  Withdraw  184.22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Directorio base correcto\n",
    "base_dir = Path(\"data\")\n",
    "\n",
    "# Archivos esperados\n",
    "files = {\n",
    "    \"affiliates\": base_dir / \"affiliates.csv\",\n",
    "    \"players\": base_dir / \"players.csv\",\n",
    "    \"transactions\": base_dir / \"transactions.csv\"\n",
    "}\n",
    "\n",
    "# Verificar existencia\n",
    "for name, path in files.items():\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"No se encontró el archivo: {path.resolve()}\")\n",
    "\n",
    "# Leer archivos\n",
    "affiliates = pd.read_csv(files[\"affiliates\"])\n",
    "players = pd.read_csv(files[\"players\"])\n",
    "transactions = pd.read_csv(files[\"transactions\"])\n",
    "\n",
    "print(\"Shapes:\", len(affiliates), len(players), len(transactions))\n",
    "display(\n",
    "    affiliates.head(3),\n",
    "    players.head(3),\n",
    "    transactions.head(3)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed duplicate IDs: {'affiliates': 0, 'players': 1, 'transactions': 0}\n",
      "Orphan transactions: 0\n",
      "Duplicate affiliate codes: 0 rows: 0\n",
      "Transactions by non-KYC players: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 10, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper functions for validation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_col(df, candidates):\n",
    "    cols_lc = {c.lower(): c for c in df.columns}\n",
    "    for cand in candidates:\n",
    "        if cand in cols_lc:\n",
    "            return cols_lc[cand]\n",
    "    for c in df.columns:\n",
    "        cl = c.lower()\n",
    "        for cand in candidates:\n",
    "            if cand in cl:\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "def coerce_bool(series):\n",
    "    if series.dtype == bool:\n",
    "        return series\n",
    "    mapping = {'true': True,'false': False,'yes': True,'no': False,'y': True,'n': False,'1': True,'0': False,1: True,0: False}\n",
    "    return series.map(lambda x: mapping.get(str(x).strip().lower(), np.nan))\n",
    "\n",
    "def ensure_unique_ids(df, id_col):\n",
    "    if id_col is None or id_col not in df.columns:\n",
    "        return df.copy(), []\n",
    "    dup_mask = df[id_col].duplicated(keep='first')\n",
    "    removed = df.loc[dup_mask, id_col].tolist()\n",
    "    return df.loc[~dup_mask].copy(), removed\n",
    "\n",
    "def parse_datetime_safe(s):\n",
    "    try:\n",
    "        return pd.to_datetime(s, errors='coerce', utc=True)\n",
    "    except Exception:\n",
    "        return pd.to_datetime(pd.Series(s), errors='coerce', utc=True)\n",
    "\n",
    "# Identify key columns\n",
    "aff_id_col = find_col(affiliates, [\"affiliate_id\", \"id\"])\n",
    "ply_id_col = find_col(players, [\"player_id\", \"id\"])\n",
    "txn_id_col = find_col(transactions, [\"transaction_id\", \"id\"])\n",
    "\n",
    "aff_owner_player_col = find_col(affiliates, [\"player_id\", \"owner_player_id\", \"affiliate_owner_player_id\"])\n",
    "txn_player_fk = find_col(transactions, [\"player_id\", \"playerid\"])\n",
    "\n",
    "aff_code_col = find_col(affiliates, [\"affiliate_code\", \"code\", \"ref_code\", \"invite_code\"])\n",
    "ply_redeemed_code_col = find_col(players, [\"affiliate_code_redeemed\", \"affiliate_code_used\", \"affiliate_code\", \"ref_code\", \"invite_code\"])\n",
    "\n",
    "ply_kyc_bool_col = find_col(players, [\"kyc_verified\", \"is_kyc_verified\", \"kyc\"])\n",
    "ply_kyc_date_col = find_col(players, [\"kyc_verified_at\", \"kyc_completed_at\", \"kyc_date\"])\n",
    "txn_date_col = find_col(transactions, [\"created_at\", \"transaction_date\", \"timestamp\", \"date\"])\n",
    "\n",
    "# Coerce types\n",
    "if ply_kyc_bool_col:\n",
    "    players[ply_kyc_bool_col] = coerce_bool(players[ply_kyc_bool_col])\n",
    "if ply_kyc_date_col:\n",
    "    players[ply_kyc_date_col] = parse_datetime_safe(players[ply_kyc_date_col])\n",
    "if txn_date_col:\n",
    "    transactions[txn_date_col] = parse_datetime_safe(transactions[txn_date_col])\n",
    "\n",
    "violations = []\n",
    "\n",
    "# Rule 5: unique IDs\n",
    "affiliates, rem_aff = ensure_unique_ids(affiliates, aff_id_col)\n",
    "players, rem_ply = ensure_unique_ids(players, ply_id_col)\n",
    "transactions, rem_txn = ensure_unique_ids(transactions, txn_id_col)\n",
    "print(\"Removed duplicate IDs:\", {\"affiliates\": len(rem_aff), \"players\": len(rem_ply), \"transactions\": len(rem_txn)})\n",
    "\n",
    "# Referential integrity: transactions.player_id in players\n",
    "if txn_player_fk and ply_id_col:\n",
    "    orphan_txn = transactions[~transactions[txn_player_fk].isin(players[ply_id_col])]\n",
    "    print(\"Orphan transactions:\", len(orphan_txn))\n",
    "    transactions = transactions[transactions[txn_player_fk].isin(players[ply_id_col])].copy()\n",
    "\n",
    "# Rule 2/3: affiliate code mapping\n",
    "if aff_code_col is not None:\n",
    "    dup_codes = affiliates[aff_code_col][affiliates[aff_code_col].duplicated(keep=False)]\n",
    "    print(\"Duplicate affiliate codes:\", dup_codes.nunique(), \"rows:\", dup_codes.shape[0])\n",
    "    # keep first per code\n",
    "    affiliates = affiliates.drop_duplicates(subset=[aff_code_col], keep='first').copy()\n",
    "\n",
    "if ply_redeemed_code_col and aff_code_col:\n",
    "    missing_code = players[players[ply_redeemed_code_col].notna() & ~players[ply_redeemed_code_col].isin(affiliates[aff_code_col])]\n",
    "    print(\"Players with non-existent redeemed code:\", len(missing_code))\n",
    "    players.loc[players[ply_redeemed_code_col].isin(missing_code[ply_redeemed_code_col]), ply_redeemed_code_col] = np.nan\n",
    "\n",
    "if aff_owner_player_col and ply_id_col:\n",
    "    bad_owner = affiliates[~affiliates[aff_owner_player_col].isin(players[ply_id_col])]\n",
    "    print(\"Affiliates with missing owner player:\", len(bad_owner))\n",
    "    affiliates = affiliates[affiliates[aff_owner_player_col].isin(players[ply_id_col])].copy()\n",
    "\n",
    "# Rule 1: KYC before transactions\n",
    "if txn_player_fk and ply_kyc_bool_col:\n",
    "    kyc_map = players.set_index(ply_id_col)[ply_kyc_bool_col].to_dict()\n",
    "    not_kyc = transactions[transactions[txn_player_fk].map(kyc_map).fillna(False) == False]\n",
    "    print(\"Transactions by non-KYC players:\", len(not_kyc))\n",
    "    transactions = transactions[transactions[txn_player_fk].map(kyc_map).fillna(False)].copy()\n",
    "\n",
    "if txn_player_fk and ply_kyc_date_col and txn_date_col:\n",
    "    kyc_date_map = players.set_index(ply_id_col)[ply_kyc_date_col].to_dict()\n",
    "    mask = transactions[txn_date_col] < transactions[txn_player_fk].map(kyc_date_map)\n",
    "    mask = mask.fillna(False)\n",
    "    before_kyc = transactions[mask]\n",
    "    print(\"Transactions before KYC date:\", len(before_kyc))\n",
    "    transactions = transactions[~mask].copy()\n",
    "\n",
    "# Save cleaned\n",
    "clean_dir = base_dir / \"cleaned\"\n",
    "clean_dir.mkdir(exist_ok=True)\n",
    "affiliates.to_csv(clean_dir / \"affiliates_clean.csv\", index=False)\n",
    "players.to_csv(clean_dir / \"players_clean.csv\", index=False)\n",
    "transactions.to_csv(clean_dir / \"transactions_clean.csv\", index=False)\n",
    "\n",
    "len(affiliates), len(players), len(transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Extend to 1000 Rows per Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK ✅ Datos extendidos y validados \n",
      "Affiliates:   1000 \n",
      "Players:      1000 \n",
      "Transactions: 1000 \n",
      "Archivos en:  /Users/jfts/Documents/ancientg/EDA_and_Generation/data/extended_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/18/8hb3mrl17z58hycjwy8kspt00000gn/T/ipykernel_36909/3945220213.py:202: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['DK0TB2VK' 'IRY7BF52' '2O0J9L8T' 'VQE7YAS4' 'MU3O32RE' 'JA4NQGHR'\n",
      " 'CP9CTRT6' '5L6CQN0W' 'QRGR0HH4' 'DCT529QN' '0XMREARM' 'SF06Y4ZP'\n",
      " 'RE5F8FNP' 'ENJ9VY7W' 'H4J84NET' 'UG3QYN82' 'W5KS3BDU' 'JWMYC19H'\n",
      " 'MRUG72XF' '4D0JIICP' 'K34GKW0G' '04HFVALU' 'NCSZJNIS' '9JNWHVOL'\n",
      " 'I8CX8ZJP' 'N3UBFXEQ' 'GZ6IAUJ4' 'UG3QYN82' 'X0RRUPNK' 'V2G5DM56'\n",
      " 'AJ32LJI8' 'J5TCYZHA' 'CWT9PS86' 'E50HX378' '8LXY4SCK' 'YAFGLUCL'\n",
      " 'I6J1YV31' 'R6QCMFXW' 'BS49TODF' '0EVN0F7O' 'H3LTCM2D' '2O0J9L8T'\n",
      " '6PH42POM' 'KJX6JMFE' 'Z4J7P31L' '9Y41OXNO' 'XDHSUUV6' '0XMREARM'\n",
      " 'WYYEGIDY' 'STEHZLNU' '7QW30S8L' 'NM6LYS2G' 'US1V5WQI' 'KVQ5DFL1'\n",
      " 'FCPV0YV5' 'YN29UVDG' '14LEBD9R' 'ZQ7RU2NB' 'OE8YBWJ5' 'YJ2IPGDV'\n",
      " 'R3MR875M' 'SX10S84U' '89Z14T3W' 'QYRXALSO' '2026PHU1' 'M0CEM46X'\n",
      " 'GVBH1DC2' '109QZ4KF' '558LDYCA' 'VQE7YAS4' 'ECLYGEMI' '0WNIQ2TJ'\n",
      " 'ARNJ03Q7' 'DV4QP5NH' 'UFF8J0RC' 'EO3TGC0S' '0UOS163O' 'B5GONABL'\n",
      " 'VEJ5M0TE' 'PBHQG6BS' '77NAO0NL' '7WNVVXCG' 'SYYUBKX9' 'RNXBYFBK'\n",
      " 'XY099R9V' 'ZHWJSQMH' '4JSGFB23' 'BGBXFIQ1' 'B630LZQW' 'MLGUXW71'\n",
      " '62EMO3Z5' 'J0L1TVJF' 'SWE7XUT0' 'HT2SZ6GG' 'QHKESM84' 'UJS6I756'\n",
      " 'POIUYT' 'LUPW0734' '6PH42POM' 'A4PSE3AX' '0DEX0ZZR' 'YCGYAOYW'\n",
      " 'A4PSE3AX' 'X2135H86' 'BW0KZLTC' 'TFFOZS24' 'M0X68FPR' 'FBWFWC00'\n",
      " 'JJJ57E02' 'B08R72JK' 'P6KLQ485' 'W2IR1DJ7' 'DK616O85' 'Y17VTCS3'\n",
      " 'FAHPWRKQ' 'POIUYT' '76PLA2KE' 'EBVFXLOW' 'SPHOO2MR' 'HFNNLGDI'\n",
      " 'WHIGJQ9C' 'C686CUIW' 'J4F7ODTB' 'G12Y2EIH' '28XIJSH5' 'EN1JKHMM'\n",
      " '8V4NNDMC' '4UWU8HI4' 'SWE7XUT0' 'I5KL6RWV' 'YAFGLUCL' '4SL4IVZ3'\n",
      " 'B630LZQW' 'BV4A48A8' 'MLGUXW71' '7CB11AR5' '0P0XTFNI' 'J4UW6TET'\n",
      " 'YCGYAOYW' 'UFF8J0RC' 'Y90MCNWF' 'V6S7RITB' 'JFSAK0YE' 'WOB6F51Q'\n",
      " 'CWT9PS86' 'WSF6PUNX' 'FILAVGSH' 'FU08XYYN' 'YFFVUQTF' 'M0VK2423'\n",
      " '3EHY1XLF' 'EW5NSGRQ' 'GD6Z4C2K' 'Y17VTCS3' '1Z0AETGS' 'CPWTZBSW'\n",
      " '0Q101W1S' 'A8J6WGUI' 'OXK4XANL' 'HBQ2YGAP' 'FBWFWC00' 'BUPCTK7A'\n",
      " 'DELU5F1L' 'UDLP42ST' 'IYCSYSKF' '9Y41OXNO' '3ZP3GCMP' 'JWO0X9EJ'\n",
      " '1RUCRQ50' 'PJ3G2Z79' 'PNQSVITW' 'T37FHBZ3' 'GZ6IAUJ4' 'HX1JA78G'\n",
      " 'L5WK4E35' 'RWBS0SK9' 'YY3PYCYV' 'MT0QAGWO' 'UHGXEX88' 'GVBH1DC2'\n",
      " '1AEHFLRR' 'LTFEBFDC' 'YS51HBR1' 'IRVUC295' 'WYYEGIDY' 'BTO3HYRD'\n",
      " 'J8YU2UDG' 'JN0PQE5I' '8WYKYCUG' '060URB7Z' '383NE17L' '9LUIVNS8'\n",
      " 'US1V5WQI' 'D2OBYMZP' 'ASDFGH' '4D0JIICP' '6IMZKH1W' '9MCYW9NT'\n",
      " '3J5DQHNO' 'XRQ8GZ21' 'X0W8UJPJ' 'EJ8204MF' 'HZA1DXCD' 'T2AVSMV2'\n",
      " 'D3YP7FE8' 'GLD3TD9X' '970HTP88' '4POMFT41' 'W8HYK0PY' 'F0CXDAZH'\n",
      " 'J8YU2UDG' '1AEHFLRR' 'VNK0RWOZ' 'MRUG72XF' 'OE7AH47W' 'BUV66UH2'\n",
      " '0XMREARM' 'Q0C5FVPU' '2TCHRKE2' 'G92OKS0T' 'K2GMJ5V9' 'NM6M1YR0'\n",
      " '2NVH17L6' '07VHZVPJ' 'SV3V9FM2' 'F8VEE2IN' 'K2GMJ5V9' 'IRVUC295'\n",
      " 'JNY2T6V7' 'QG5FQ4HV' 'X5F5G90W' 'RIX92UT8' '7HJ0MQ3J' 'X1HT4D1F'\n",
      " 'CHAMP14R' 'K2GMJ5V9' 'SCPWU5A0' 'Z3ER2W77' '8HGKCHCA' '2NVH17L6'\n",
      " 'XDYXPY8A' '3WBKH5GX' 'EJ8204MF' 'SYYQI10M' 'IVVYJNNN' 'HGX075P5'\n",
      " 'W2IR1DJ7' 'F0CXDAZH' 'Z89A0FZ1' '6PH42POM' 'FBAYPH4Z' '0OGO3XSR'\n",
      " 'EDZVNGF6' '14LEBD9R' 'BUCC8LFI' 'AMPRN8QJ' 'RV54ZTR8' '9ENUCVFR'\n",
      " '4OUQ1395' 'UIMHMWR8' '1QVJS46Q' '76PLA2KE' 'NMZPZ4D6' 'WYQS85HK'\n",
      " 'HM2X4873' '4Y1IO345' '62HPU0JV' '6DV7BOXN' 'POIUYT' '72GTQP3O'\n",
      " '0S5TSKAU' 'GT7H2ZRE' 'CPWTZBSW' 'BFU531YO' 'M0CEM46X' 'SEBFOCCJ'\n",
      " 'TI9DJT0Z' 'QO4PXPVU' '9VIO1W5N' 'V2FRM3TU' '6GRD0INC' 'KQE4T5P8'\n",
      " 'J4UW6TET' 'VX95U69H' 'DELU5F1L' '14LEBD9R' '04HFVALU' '0RQ703Z3'\n",
      " 'GZ50HSES' 'MKXQ2ZQD' 'W0HK628T' 'CUQJ7OPU' 'Z3R5FVYA' '0FCQXW19'\n",
      " 'TFFOZS24' 'P6KLQ485' '4AIZLTVQ' '2QULJNNP' '55LA6LE7' 'MJH8LB5S'\n",
      " 'EHT6GIXQ' 'UC0GBRWV' '5JKHQTGE' 'X5F5G90W' 'J8YU2UDG' '0EVN0F7O'\n",
      " 'S6U1JTYU' 'T81ZOSAQ' 'QWJ8YMBH' 'XI7CVQDC' 'NHJW73VN' '5SRT7070'\n",
      " 'CFKZPZXU' '0Q101W1S' 'TH82ES10' '0ERJ63LY' 'PNQSVITW' '1UQNCCCD'\n",
      " 'OW1QEU5T' 'YHQ09NQT' 'LTFEBFDC' 'TS2PG81T' '62HPU0JV' '95RXR18M'\n",
      " 'ETMWW2MB' '9XBZ8FEQ' 'SRTTTC1W' 'JM4A0UXU' '69SLDH0L' 'D9CBC8OJ'\n",
      " 'AA4AZAJ1' 'D7WL5YE4' 'CK9GBMVX' '3PVAV49M' 'XBIFV1WF' '4Y1IO345'\n",
      " 'N79O3ABF' '1353CJFA' '25IN6LQ4' 'C9IE1Z5O' 'XTRN8Z8G' 'DWEHSP'\n",
      " 'AS13Z61M' 'DGVIMGZ4' 'OO4YCJ0V' 'NJC1X0GI' 'U024OEL2' '0NUQVBVT'\n",
      " 'RBGKEMM5' '9ENUCVFR' '80881K1I' '14LEBD9R' 'SPVMSCCK' 'SRTTTC1W'\n",
      " '2Q1C04IM' '0ERJ63LY' 'FU08XYYN' '07VHZVPJ' 'QG5FQ4HV' '22B1WQW8'\n",
      " '1UQNCCCD' 'QVK217BU' 'WTW6X32V' 'IRVUC295' 'MJH8LB5S' 'YY3PYCYV'\n",
      " 'IVVYJNNN' 'EOFSXMOH' '6HNLIEEX' 'E0KLTIVW' 'X2135H86' 'AXONMTH3'\n",
      " 'DSL1EC0W' '8WYKYCUG' 'DCT529QN' '08N7OQAC' 'T93WTQ3I' '3EK2FCJL'\n",
      " 'DELU5F1L' 'K34GKW0G' 'R3PIYDT1' '0SO4T0V1' '6222O5XX' 'R7NAWIPI'\n",
      " '95RXR18M' 'BUCC8LFI' 'KCMGRMVB' 'QBQN6PHL' '74BW1BG1' 'V1Y1ZM4Y'\n",
      " 'XG2OCLLW' 'JZVQPEOB' 'CTXRA30N' 'X0RRUPNK' 'Y2VDO71A' 'C2FGLC9M'\n",
      " '9VMYBJY5' 'POIUYT' '5JY5HF7F' '8JCIOL6D' '4AIZLTVQ' 'UIMHMWR8'\n",
      " '5PJURHBD' 'Z3ER2W77' 'BTO3HYRD' 'BQQGSEEJ' 'CIU24JKM' '95RXR18M'\n",
      " 'WDUBX057' '2S1AZ41R' 'C4JQ9K1O' 'JOL4V68C' 'M08PVYOR' 'H36QG89X'\n",
      " 'WYY3RTUK' '3EHY1XLF' '53LCKKPS' 'OV72WHWK' '58C2WCZT' '6XUGFJ9A'\n",
      " 'Z89A0FZ1' 'SYYQI10M' 'YFFVUQTF' 'WDUBX057' '6HDF19C3' '37KICORS'\n",
      " 'QD443B82' 'OZS1QB16' 'YEZ5AZHG' 'BZOQYGH6' '5PJURHBD' '9EI6S00X'\n",
      " 'IP1DOWMG' 'UZBWBCQ6' '8NCPIEXK' 'I57EZX15' '455XVLED' '05BE6TLY'\n",
      " 'HOKKBOEQ' 'W5KS3BDU' 'ZDHFVHCQ' '5SRT7070' 'N3UBFXEQ' 'XATGCSX2'\n",
      " 'V3U3INKS' '07VHZVPJ' 'HCN09OV8' '283FUJIA' 'PSXFEFNV' 'NCSZJNIS'\n",
      " 'TB3CDZCL' 'IE0P4K4N' 'JXPQ0FQR' 'ZXCVBN' '5JKHQTGE' 'GZ50HSES'\n",
      " '61CRZY4S' 'EYGQ4XK8' 'ZO3KT6LK' '0653506S' 'JPCGUUXL' 'ZVYOFMME'\n",
      " 'DK0TB2VK' 'ZFECPG24' 'D9SRAV7U' '04HFVALU' '4SL4IVZ3' 'HN4A5MYV'\n",
      " 'SEBFOCCJ' 'WYY3RTUK' '2Q1C04IM' 'MRNE6MIY' '0PFSM0HB' 'ZJLKREB2'\n",
      " '4D0JIICP' '0YMUYBB4' 'AUV3SA8R' 'XDHSUUV6' '2S4N4H8L' 'KJPTFKRN'\n",
      " '98AZ6ZOZ' 'QWJ8YMBH' 'J8YU2UDG' 'TI9DJT0Z' 'CK9GBMVX' '5PJURHBD'\n",
      " '6XUGFJ9A' 'VKQ5U5W6' '08N7OQAC' 'YPV7UNXU' '91D8058W' 'U024OEL2'\n",
      " 'ZO3KT6LK' 'NH7JCDTI' 'QG5FQ4HV' 'S6TWEEYR' 'O4R7OYAD' 'WSF6PUNX'\n",
      " '7XMIXVC5' 'G2CF9NIQ' 'KSD2ZR0L' '8VDY69WA' 'WE08UQGA' '4JSGFB23'\n",
      " 'QTFDIKJM' 'JTKIXMTC' 'WZSAWRG5' 'JA4NQGHR' 'UYL21SUA' '3ZP3GCMP'\n",
      " 'OS7D2681' '8LXY4SCK' 'GVBH1DC2' 'EFI33JK9' 'SF06Y4ZP' 'K9Z04JXL'\n",
      " 'FA5HTZTY' 'CF5KR1VI' 'DK616O85' '2ZVDRHDP' 'US1V5WQI' '7ARXP4FP'\n",
      " 'TM30OI62' 'TH82ES10' 'S9DSOXB4' 'G92OKS0T' 'D5809Q9M' 'WP60MSSL'\n",
      " '8LXY4SCK' 'QVYBRD6O' 'JWO0X9EJ' 'GU26UVCC' '25IN6LQ4' 'KD1CIW4N'\n",
      " '1QVJS46Q' '6SXKJU7Q' 'WD9SZ9A1' 'MP35XS72' '76PLA2KE' 'J5TCYZHA'\n",
      " 'C80WV9PT' 'JXQ5W9GY' 'S1ZFY8LR' '37KICORS' '2DXQF0EJ' 'QO4PXPVU'\n",
      " 'DV4QP5NH' '2026PHU1' 'JQJD5R3K' '5JY5HF7F' 'Z3R5FVYA' 'UKJBTZGN'\n",
      " '6IMZKH1W' '80YVJZU9' 'D5606R1V' '67XMSNOS' 'H7RGSW6R' '455XVLED'\n",
      " 'S6TWEEYR' 'T81ZOSAQ' 'POIUYT' 'ZQ7RU2NB' '8HGKCHCA' '1XO3V2KX'\n",
      " 'R3PIYDT1' 'PNQSVITW' 'W9ZPJWAK' '74BW1BG1' 'IRYSAWL2' '8H4RUGRZ'\n",
      " 'JM4A0UXU' '8B8XJS7H' 'MDIMY7W7' '08N7OQAC' 'VUALVYFM' 'VPL0JT98'\n",
      " 'NLPVDOY6' 'A2KE0EQV' 'OPGWAJF9' 'I8CX8ZJP' 'XDYXPY8A' 'HGX075P5'\n",
      " '22B1WQW8' 'KJX6JMFE' '95RXR18M' 'T7ED4QT3' 'AXONMTH3' 'WZNQ3R95'\n",
      " 'HOKKBOEQ' '6KV7TKGG' 'UZBWBCQ6' 'W8HYK0PY' 'DGHRUDKZ' 'G2CF9NIQ'\n",
      " 'IE0P4K4N' '7HC9MSLE' 'YY3PYCYV' '7NLIWF4V' 'EFI33JK9' 'K2T2Q1OW'\n",
      " 'HFNNLGDI' '303KVRSR' 'ZHWJSQMH' 'CK9GBMVX' 'WQZZOWI9' 'Z3R5FVYA'\n",
      " 'OI7KA8A2' 'I57EZX15' 'JWMYC19H' 'MKXQ2ZQD' 'US3W3W9C' 'BONYFUOX'\n",
      " 'DV5XTSDO' 'QV4NNX0N' 'F3DJ9T9I' 'D6ZSQ563' 'OW1QEU5T' 'F5ZE4ZVV'\n",
      " '8LXY4SCK']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  players_ext.loc[assign_mask, ply_redeemed_code_col] = rng.choice(valid_aff_codes, size=n_assign)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random, string\n",
    "from datetime import timedelta\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 1) Paths inteligentes (detecta 'EDA_and_Generation/data' o 'data')\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "candidates = [Path(\"EDA_and_Generation/data\"), Path(\"data\")]\n",
    "for cand in candidates:\n",
    "    if (cand / \"cleaned\" / \"affiliates_clean.csv\").exists():\n",
    "        base_dir = cand\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        \"No encontré la carpeta data. Esperaba EDA_and_Generation/data o data \"\n",
    "        \"con los archivos cleaned/*.csv\"\n",
    "    )\n",
    "\n",
    "clean_dir = base_dir / \"cleaned\"\n",
    "ext_dir = base_dir / \"extended_1000\"\n",
    "ext_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 2) Lectura de datos limpios\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "affiliates = pd.read_csv(clean_dir / \"affiliates_clean.csv\")\n",
    "players = pd.read_csv(clean_dir / \"players_clean.csv\")\n",
    "transactions = pd.read_csv(clean_dir / \"transactions_clean.csv\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 3) Utilidades\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "def find_col(df, candidates):\n",
    "    \"\"\"Busca una columna por nombre exacto (case-insensitive) o por contains.\"\"\"\n",
    "    cols_lc = {c.lower(): c for c in df.columns}\n",
    "    for cand in candidates:\n",
    "        if cand in cols_lc:\n",
    "            return cols_lc[cand]\n",
    "    for c in df.columns:\n",
    "        cl = c.lower()\n",
    "        for cand in candidates:\n",
    "            if cand in cl:\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "def random_code(n=8):\n",
    "    import string, random\n",
    "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=n))\n",
    "\n",
    "def next_numeric_id(existing_ids):\n",
    "    \"\"\"Generador de IDs numéricos crecientes detectando máximo actual.\"\"\"\n",
    "    try:\n",
    "        s = pd.Series(list(existing_ids)).copy()\n",
    "        s_num = pd.to_numeric(s, errors='coerce')\n",
    "        mx = int(np.nanmax(s_num)) if not np.all(np.isnan(s_num)) else 0\n",
    "    except Exception:\n",
    "        mx = 0\n",
    "    cur = mx + 1\n",
    "    while True:\n",
    "        yield cur\n",
    "        cur += 1\n",
    "\n",
    "# Fechas siempre en UTC (aware)\n",
    "NOW_UTC = pd.Timestamp.now(tz=\"UTC\")\n",
    "\n",
    "def _coerce_utc(series):\n",
    "    return pd.to_datetime(series, errors=\"coerce\", utc=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "target = 1000\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 4) Identificación de columnas por heurística\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "aff_id_col = find_col(affiliates, [\"affiliate_id\", \"id\"])\n",
    "ply_id_col = find_col(players, [\"player_id\", \"id\"])\n",
    "txn_id_col = find_col(transactions, [\"transaction_id\", \"id\"])\n",
    "aff_owner_player_col = find_col(affiliates, [\"player_id\", \"owner_player_id\", \"affiliate_owner_player_id\"])\n",
    "txn_player_fk = find_col(transactions, [\"player_id\", \"playerid\"])\n",
    "aff_code_col = find_col(affiliates, [\"affiliate_code\", \"code\", \"ref_code\", \"invite_code\"])\n",
    "ply_redeemed_code_col = find_col(players, [\"affiliate_code_redeemed\", \"affiliate_code_used\", \"affiliate_code\", \"ref_code\", \"invite_code\"])\n",
    "ply_kyc_bool_col = find_col(players, [\"kyc_verified\", \"is_kyc_verified\", \"kyc\", \"is_kyc_approved\"])\n",
    "ply_kyc_date_col = find_col(players, [\"kyc_verified_at\", \"kyc_completed_at\", \"kyc_date\"])\n",
    "txn_date_col = find_col(transactions, [\"created_at\", \"transaction_date\", \"timestamp\", \"date\"])\n",
    "created_col = find_col(players, [\"created_at\", \"signup_at\", \"joined_at\", \"date_joined\"])\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 5) Extender affiliates\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "aff_cols = affiliates.columns.tolist()\n",
    "existing_codes = set(affiliates[aff_code_col].dropna().astype(str)) if aff_code_col else set()\n",
    "owner_pool = players[ply_id_col].tolist() if (aff_owner_player_col and ply_id_col and ply_id_col in players.columns) else []\n",
    "id_gen_aff = next_numeric_id(affiliates[aff_id_col] if aff_id_col else [])\n",
    "\n",
    "n_needed = max(0, target - len(affiliates))\n",
    "aff_new = []\n",
    "for _ in range(n_needed):\n",
    "    row = {c: np.nan for c in aff_cols}\n",
    "    if aff_id_col:\n",
    "        row[aff_id_col] = next(id_gen_aff)\n",
    "    if aff_code_col:\n",
    "        code = random_code(8)\n",
    "        while code in existing_codes:\n",
    "            code = random_code(8)\n",
    "        row[aff_code_col] = code\n",
    "        existing_codes.add(code)\n",
    "    if aff_owner_player_col and owner_pool:\n",
    "        row[aff_owner_player_col] = int(rng.choice(owner_pool))\n",
    "    aff_new.append(row)\n",
    "\n",
    "affiliates_ext = pd.concat([affiliates, pd.DataFrame(aff_new)], ignore_index=True)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 6) Extender players\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "ply_cols = players.columns.tolist()\n",
    "id_gen_ply = next_numeric_id(players[ply_id_col] if ply_id_col else [])\n",
    "aff_codes_all = set(affiliates_ext[aff_code_col].dropna().astype(str)) if aff_code_col else set()\n",
    "\n",
    "n_needed = max(0, target - len(players))\n",
    "ply_new = []\n",
    "for _ in range(n_needed):\n",
    "    row = {c: np.nan for c in ply_cols}\n",
    "    if ply_id_col:\n",
    "        row[ply_id_col] = next(id_gen_ply)\n",
    "    if created_col:\n",
    "        row[created_col] = NOW_UTC - pd.Timedelta(days=int(rng.integers(0, 120))) - pd.Timedelta(minutes=int(rng.integers(0, 1440)))\n",
    "    if ply_kyc_bool_col:\n",
    "        row[ply_kyc_bool_col] = bool(rng.choice([True, False], p=[0.75, 0.25]))\n",
    "    if ply_kyc_date_col:\n",
    "        if row.get(ply_kyc_bool_col, True) is True:\n",
    "            base_dt = row.get(created_col, NOW_UTC - pd.Timedelta(days=int(rng.integers(5, 90))))\n",
    "            if pd.isna(base_dt):\n",
    "                base_dt = NOW_UTC - pd.Timedelta(days=int(rng.integers(5, 90)))\n",
    "            row[ply_kyc_date_col] = pd.to_datetime(base_dt, utc=True) + pd.Timedelta(days=int(rng.integers(0, 10)))\n",
    "        else:\n",
    "            row[ply_kyc_date_col] = pd.NaT\n",
    "    if ply_redeemed_code_col and aff_codes_all and rng.random() < 0.6:\n",
    "        row[ply_redeemed_code_col] = rng.choice(list(aff_codes_all))\n",
    "    ply_new.append(row)\n",
    "\n",
    "players_ext = pd.concat([players, pd.DataFrame(ply_new)], ignore_index=True)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 7) Normalización de vacíos/códigos\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "def _normalize_na(df, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "def _normalize_code_series(s):\n",
    "    return (\n",
    "        s.astype(str)\n",
    "         .str.strip()\n",
    "         .str.upper()\n",
    "         .replace(r'^\\s*$', np.nan, regex=True)\n",
    "    )\n",
    "\n",
    "aff_cols_maybe_empty = []\n",
    "if 'origin' in affiliates_ext.columns: aff_cols_maybe_empty.append('origin')\n",
    "if 'redeemed_at' in affiliates_ext.columns: aff_cols_maybe_empty.append('redeemed_at')\n",
    "_normalize_na(affiliates_ext, aff_cols_maybe_empty)\n",
    "\n",
    "ply_cols_maybe_empty = []\n",
    "if 'affiliate_id' in players_ext.columns: ply_cols_maybe_empty.append('affiliate_id')\n",
    "_normalize_na(players_ext, ply_cols_maybe_empty)\n",
    "\n",
    "if aff_code_col and aff_code_col in affiliates_ext.columns:\n",
    "    affiliates_ext[aff_code_col] = _normalize_code_series(affiliates_ext[aff_code_col])\n",
    "if ply_redeemed_code_col and ply_redeemed_code_col in players_ext.columns:\n",
    "    players_ext[ply_redeemed_code_col] = _normalize_code_series(players_ext[ply_redeemed_code_col])\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 8) Si players no tiene código redimido, crear temporalmente y poblar (~60%)\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "created_temp_redeemed_col = False\n",
    "if not ply_redeemed_code_col:\n",
    "    ply_redeemed_code_col = \"affiliate_code_redeemed\"\n",
    "    if ply_redeemed_code_col not in players_ext.columns:\n",
    "        players_ext[ply_redeemed_code_col] = np.nan\n",
    "        created_temp_redeemed_col = True\n",
    "\n",
    "valid_aff_codes = []\n",
    "if aff_code_col and aff_code_col in affiliates_ext.columns:\n",
    "    valid_aff_codes = (\n",
    "        affiliates_ext[aff_code_col]\n",
    "        .astype(str).str.strip().str.upper()\n",
    "        .replace(r'^\\s*$', np.nan, regex=True)\n",
    "        .dropna().unique().tolist()\n",
    "    )\n",
    "\n",
    "if valid_aff_codes:\n",
    "    mask_no_code = players_ext[ply_redeemed_code_col].replace(r'^\\s*$', np.nan, regex=True).isna()\n",
    "    if mask_no_code.any():\n",
    "        assign_mask = mask_no_code & (rng.random(len(players_ext)) < 0.60)\n",
    "        n_assign = int(assign_mask.sum())\n",
    "        if n_assign > 0:\n",
    "            players_ext.loc[assign_mask, ply_redeemed_code_col] = rng.choice(valid_aff_codes, size=n_assign)\n",
    "\n",
    "# normaliza de nuevo el código redimido tras poblar\n",
    "players_ext[ply_redeemed_code_col] = (\n",
    "    players_ext[ply_redeemed_code_col]\n",
    "    .astype(str).str.strip().str.upper()\n",
    "    .replace(r'^\\s*$', np.nan, regex=True)\n",
    ")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 9) Columnas extra (origin, redeemed_at, affiliate_id, country_code, updated_at)\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# affiliates.origin (solo completa faltantes)\n",
    "if \"origin\" not in affiliates_ext.columns:\n",
    "    affiliates_ext[\"origin\"] = np.nan\n",
    "origin_pool = [\"web\", \"ios\", \"android\", \"partner\", \"campaign\", \"YouTube\", \"Discord\", \"X\"]\n",
    "mask_origin = affiliates_ext[\"origin\"].isna()\n",
    "if mask_origin.any():\n",
    "    affiliates_ext.loc[mask_origin, \"origin\"] = rng.choice(origin_pool, size=int(mask_origin.sum()))\n",
    "\n",
    "# affiliates.redeemed_at (best-of created_at/updated_at/kyc_date) + jitter\n",
    "if \"redeemed_at\" not in affiliates_ext.columns:\n",
    "    affiliates_ext[\"redeemed_at\"] = pd.NaT\n",
    "else:\n",
    "    affiliates_ext[\"redeemed_at\"] = affiliates_ext[\"redeemed_at\"].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    affiliates_ext[\"redeemed_at\"] = _coerce_utc(affiliates_ext[\"redeemed_at\"])\n",
    "\n",
    "date_candidates = []\n",
    "if created_col and created_col in players_ext.columns:\n",
    "    date_candidates.append(created_col)\n",
    "if \"updated_at\" in players_ext.columns:\n",
    "    date_candidates.append(\"updated_at\")\n",
    "if ply_kyc_date_col and ply_kyc_date_col in players_ext.columns:\n",
    "    date_candidates.append(ply_kyc_date_col)\n",
    "\n",
    "# Columna temporal en UTC para evitar FutureWarning\n",
    "tmp_date_col = \"__best_player_date__\"\n",
    "players_ext[tmp_date_col] = pd.Series(pd.NaT, index=players_ext.index, dtype=\"datetime64[ns, UTC]\")\n",
    "\n",
    "if aff_code_col and ply_redeemed_code_col and date_candidates:\n",
    "    for c in date_candidates:\n",
    "        if c in players_ext.columns:\n",
    "            mask_tmp = players_ext[tmp_date_col].isna()\n",
    "            if mask_tmp.any():\n",
    "                players_ext.loc[mask_tmp, tmp_date_col] = _coerce_utc(players_ext.loc[mask_tmp, c])\n",
    "\n",
    "    used = players_ext.dropna(subset=[ply_redeemed_code_col])\n",
    "    if not used.empty:\n",
    "        used_codes_norm = used[ply_redeemed_code_col].astype(str).str.strip().str.upper()\n",
    "        code_to_first = (\n",
    "            pd.DataFrame({\n",
    "                \"code_norm\": used_codes_norm,\n",
    "                \"first_dt\": _coerce_utc(used[tmp_date_col])\n",
    "            })\n",
    "            .dropna(subset=[\"first_dt\"])\n",
    "            .groupby(\"code_norm\", as_index=True)[\"first_dt\"]\n",
    "            .min()\n",
    "        )\n",
    "\n",
    "        aff_code_norm = affiliates_ext[aff_code_col].astype(str).str.strip().str.upper()\n",
    "        mask_red = affiliates_ext[\"redeemed_at\"].isna()\n",
    "        if mask_red.any():\n",
    "            mapped = aff_code_norm.map(code_to_first)\n",
    "            mapped_dt = _coerce_utc(mapped)\n",
    "            affiliates_ext.loc[mask_red, \"redeemed_at\"] = mapped_dt.loc[mask_red]\n",
    "\n",
    "            # jitter a los recién rellenados\n",
    "            mask_after = affiliates_ext[\"redeemed_at\"].notna() & mask_red\n",
    "            if mask_after.any():\n",
    "                jitter = pd.to_timedelta(rng.integers(0, 60*24, size=int(mask_after.sum())), unit=\"m\")\n",
    "                affiliates_ext.loc[mask_after, \"redeemed_at\"] = affiliates_ext.loc[mask_after, \"redeemed_at\"] + jitter\n",
    "\n",
    "# players.affiliate_id (map por código → affiliate_id; completa faltantes)\n",
    "if aff_id_col and aff_code_col and ply_redeemed_code_col:\n",
    "    code_to_affid = affiliates_ext.copy()\n",
    "    code_to_affid[aff_code_col] = code_to_affid[aff_code_col].astype(str).str.strip().str.upper()\n",
    "    code_to_affid = code_to_affid.set_index(aff_code_col)[aff_id_col]\n",
    "    try:\n",
    "        code_to_affid = pd.to_numeric(code_to_affid, errors=\"coerce\").astype(\"Int64\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    code_to_affid = code_to_affid.to_dict()\n",
    "\n",
    "    if \"affiliate_id\" not in players_ext.columns:\n",
    "        players_ext[\"affiliate_id\"] = np.nan\n",
    "\n",
    "    mask_affid = players_ext[\"affiliate_id\"].replace(r'^\\s*$', np.nan, regex=True).isna()\n",
    "    if mask_affid.any():\n",
    "        players_ext.loc[mask_affid, \"affiliate_id\"] = players_ext.loc[mask_affid, ply_redeemed_code_col].map(code_to_affid)\n",
    "\n",
    "    try:\n",
    "        players_ext[\"affiliate_id\"] = pd.to_numeric(players_ext[\"affiliate_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    except Exception:\n",
    "        pass\n",
    "else:\n",
    "    if \"affiliate_id\" not in players_ext.columns:\n",
    "        players_ext[\"affiliate_id\"] = np.nan\n",
    "\n",
    "# players.country_code (no pisa existentes)\n",
    "country_pool = [\"CO\",\"US\",\"MX\",\"BR\",\"AR\",\"CL\",\"PE\",\"ES\",\"GB\",\"DE\",\"FR\",\"CA\",\"IN\",\"PH\",\"AU\"]\n",
    "if \"country_code\" not in players_ext.columns:\n",
    "    players_ext[\"country_code\"] = np.nan\n",
    "mask_cc = players_ext[\"country_code\"].isna()\n",
    "players_ext.loc[mask_cc, \"country_code\"] = rng.choice(country_pool, size=int(mask_cc.sum()))\n",
    "\n",
    "# players.updated_at ≥ created_at (o base plausible si no hay created_at)\n",
    "if \"updated_at\" not in players_ext.columns:\n",
    "    players_ext[\"updated_at\"] = pd.NaT\n",
    "\n",
    "def _rand_after(dt):\n",
    "    if pd.notna(dt):\n",
    "        base = pd.to_datetime(dt, utc=True)  # asegura aware\n",
    "    else:\n",
    "        base = pd.Timestamp.now(tz=\"UTC\") - pd.Timedelta(days=int(rng.integers(0, 120)))\n",
    "    return base + pd.Timedelta(days=int(rng.integers(0, 30))) + pd.Timedelta(minutes=int(rng.integers(0, 1440)))\n",
    "\n",
    "mask_upd = players_ext[\"updated_at\"].isna()\n",
    "if created_col and created_col in players_ext.columns:\n",
    "    players_ext.loc[mask_upd, \"updated_at\"] = [\n",
    "        _rand_after(dt) for dt in players_ext.loc[mask_upd, created_col]\n",
    "    ]\n",
    "else:\n",
    "    players_ext.loc[mask_upd, \"updated_at\"] = [\n",
    "        _rand_after(pd.NaT) for _ in range(int(mask_upd.sum()))\n",
    "    ]\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 10) Extender transactions (sólo para jugadores KYC)\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "txn_cols = transactions.columns.tolist()\n",
    "id_gen_txn = next_numeric_id(transactions[txn_id_col] if txn_id_col else [])\n",
    "\n",
    "# asegura booleanos/fechas\n",
    "if ply_kyc_bool_col and ply_kyc_bool_col in players_ext.columns:\n",
    "    players_ext[ply_kyc_bool_col] = players_ext[ply_kyc_bool_col].astype(bool)\n",
    "\n",
    "if created_col and created_col in players_ext.columns:\n",
    "    players_ext[created_col] = _coerce_utc(players_ext[created_col])\n",
    "if \"updated_at\" in players_ext.columns:\n",
    "    players_ext[\"updated_at\"] = _coerce_utc(players_ext[\"updated_at\"])\n",
    "if ply_kyc_date_col and ply_kyc_date_col in players_ext.columns:\n",
    "    players_ext[ply_kyc_date_col] = _coerce_utc(players_ext[ply_kyc_date_col])\n",
    "if \"redeemed_at\" in affiliates_ext.columns:\n",
    "    affiliates_ext[\"redeemed_at\"] = _coerce_utc(affiliates_ext[\"redeemed_at\"])\n",
    "\n",
    "kyc_map = players_ext.set_index(ply_id_col)[ply_kyc_bool_col].to_dict() if ply_kyc_bool_col else {}\n",
    "kyc_date_map = players_ext.set_index(ply_id_col)[ply_kyc_date_col].to_dict() if ply_kyc_date_col else {}\n",
    "player_pool = players_ext[ply_id_col].dropna().astype(int).tolist() if ply_id_col else []\n",
    "kyc_players = [pid for pid in player_pool if kyc_map.get(pid, False) is True]\n",
    "\n",
    "n_needed = max(0, target - len(transactions))\n",
    "txn_new = []\n",
    "for _ in range(n_needed):\n",
    "    if not kyc_players:\n",
    "        break\n",
    "    pid = int(rng.choice(kyc_players))\n",
    "    row = {c: np.nan for c in txn_cols}\n",
    "    if txn_id_col:\n",
    "        row[txn_id_col] = next(id_gen_txn)\n",
    "    if txn_player_fk:\n",
    "        row[txn_player_fk] = pid\n",
    "    if txn_date_col:\n",
    "        base_dt = kyc_date_map.get(pid, pd.Timestamp.now(tz=\"UTC\") - pd.Timedelta(days=30))\n",
    "        if pd.isna(base_dt):\n",
    "            base_dt = pd.Timestamp.now(tz=\"UTC\") - pd.Timedelta(days=30)\n",
    "        row[txn_date_col] = pd.to_datetime(base_dt, utc=True) + pd.Timedelta(days=int(rng.integers(0, 60))) + pd.Timedelta(minutes=int(rng.integers(0, 1440)))\n",
    "    # Completar columnas por tipo tomando como referencia el dtype de 'transactions'\n",
    "    for c in transactions.columns:\n",
    "        if pd.notna(row.get(c)):\n",
    "            continue\n",
    "        cl = c.lower()\n",
    "        if transactions[c].dtype == object:\n",
    "            if \"currency\" in cl:\n",
    "                row[c] = rng.choice([\"USD\",\"EUR\",\"COP\",\"BRL\"])\n",
    "            elif \"type\" in cl:\n",
    "                row[c] = rng.choice([\"deposit\",\"withdrawal\",\"bet\",\"win\"])\n",
    "            else:\n",
    "                row[c] = None\n",
    "        elif np.issubdtype(transactions[c].dtype, np.number):\n",
    "            if \"amount\" in cl or \"value\" in cl:\n",
    "                row[c] = float(int(rng.integers(1, 5000)))\n",
    "            else:\n",
    "                row[c] = float(int(rng.integers(0, 1000)))\n",
    "        elif np.issubdtype(transactions[c].dtype, np.datetime64):\n",
    "            # ya seteado txn_date_col si aplica\n",
    "            pass\n",
    "    txn_new.append(row)\n",
    "\n",
    "transactions_ext = pd.concat([transactions, pd.DataFrame(txn_new)], ignore_index=True)\n",
    "\n",
    "# coerción de fecha en transacciones (seguridad)\n",
    "if txn_date_col and txn_date_col in transactions_ext.columns:\n",
    "    transactions_ext[txn_date_col] = _coerce_utc(transactions_ext[txn_date_col])\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 11) Tipos consistentes en IDs (suave)\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "for df in [affiliates_ext, players_ext, transactions_ext]:\n",
    "    for col in [aff_id_col, ply_id_col, txn_id_col, txn_player_fk, \"affiliate_id\"]:\n",
    "        if col and col in df.columns:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"Int64\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 12) Limpieza final de columnas auxiliares\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "if \"__best_player_date__\" in players_ext.columns:\n",
    "    players_ext.drop(columns=[\"__best_player_date__\"], inplace=True)\n",
    "# elimina affiliate_code_redeemed solo si lo creamos temporalmente\n",
    "if 'created_temp_redeemed_col' in locals() and created_temp_redeemed_col and \"affiliate_code_redeemed\" in players_ext.columns:\n",
    "    players_ext.drop(columns=[\"affiliate_code_redeemed\"], inplace=True)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 13) Reglas de negocio (validaciones)\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 1. Nadie transacciona antes de estar KYC (y fecha posterior al KYC)\n",
    "if ply_kyc_bool_col and txn_player_fk and txn_date_col and ply_kyc_date_col:\n",
    "    merged = transactions_ext.merge(\n",
    "        players_ext[[ply_id_col, ply_kyc_bool_col, ply_kyc_date_col]],\n",
    "        left_on=txn_player_fk, right_on=ply_id_col, how=\"left\"\n",
    "    )\n",
    "    bad_kyc = merged[(merged[ply_kyc_bool_col] != True) | (merged[txn_date_col] < merged[ply_kyc_date_col])]\n",
    "    assert bad_kyc.empty, f\"Hay {len(bad_kyc)} transacciones violando KYC (no verificado o fecha previa al KYC).\"\n",
    "\n",
    "# 2. affiliate_id ↔ código redimido coherente (si existen ambas)\n",
    "if aff_id_col and aff_code_col and \"affiliate_id\" in players_ext.columns and ply_redeemed_code_col in players_ext.columns:\n",
    "    code_by_affid = affiliates_ext[[aff_id_col, aff_code_col]].dropna().copy()\n",
    "    code_by_affid[aff_code_col] = code_by_affid[aff_code_col].astype(str).str.strip().str.upper()\n",
    "    code_by_affid = code_by_affid.drop_duplicates(subset=[aff_id_col])\n",
    "\n",
    "    chk = players_ext.merge(code_by_affid, left_on=\"affiliate_id\", right_on=aff_id_col, how=\"left\", suffixes=(\"\",\"__aff\"))\n",
    "    mism = chk[\n",
    "        chk[\"affiliate_id\"].notna() &\n",
    "        (ply_redeemed_code_col in chk.columns) &\n",
    "        chk[ply_redeemed_code_col].notna() &\n",
    "        (chk[ply_redeemed_code_col].astype(str).str.strip().str.upper() != chk[aff_code_col].astype(str).str.strip().str.upper())\n",
    "    ]\n",
    "    assert mism.empty, f\"{len(mism)} jugadores con affiliate_id cuyo código no coincide con el código del afiliado.\"\n",
    "\n",
    "# 3. IDs únicos\n",
    "if ply_id_col:\n",
    "    assert players_ext[ply_id_col].nunique() == len(players_ext), \"player_id no es único\"\n",
    "if aff_id_col:\n",
    "    assert affiliates_ext[aff_id_col].nunique() == len(affiliates_ext), \"affiliate_id no es único\"\n",
    "if txn_id_col:\n",
    "    assert transactions_ext[txn_id_col].nunique() == len(transactions_ext), \"transaction_id no es único\"\n",
    "\n",
    "# 4. Conteos objetivo\n",
    "assert len(affiliates_ext)   >= 1000, f\"Affiliates < 1000 (={len(affiliates_ext)})\"\n",
    "assert len(players_ext)      >= 1000, f\"Players < 1000 (={len(players_ext)})\"\n",
    "assert len(transactions_ext) >= 1000, f\"Transactions < 1000 (={len(transactions_ext)})\"\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 14) Guardar\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "affiliates_ext.to_csv(ext_dir / \"affiliates_1000.csv\", index=False)\n",
    "players_ext.to_csv(ext_dir / \"players_1000.csv\", index=False)\n",
    "transactions_ext.to_csv(ext_dir / \"transactions_1000.csv\", index=False)\n",
    "\n",
    "print(\n",
    "    \"OK ✅ Datos extendidos y validados\",\n",
    "    f\"\\nAffiliates:   {len(affiliates_ext)}\",\n",
    "    f\"\\nPlayers:      {len(players_ext)}\",\n",
    "    f\"\\nTransactions: {len(transactions_ext)}\",\n",
    "    f\"\\nArchivos en:  {ext_dir.resolve()}\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
